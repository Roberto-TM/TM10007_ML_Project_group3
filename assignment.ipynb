{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "b0422a01-7764-4c7b-93a1-3687a4c8890d"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-9HbZdwFb33"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VV0YLd6oHgen"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "\n",
        "from worcgist.load_data import load_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "7ca929ff-68c3-49a5-dfb4-c01c885008af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples: 246\n",
            "The number of features: 493\n",
            "The number of datapoints: 121278\n",
            "The number of missing values: 0\n",
            "The number of zero values: 6848\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 246 entries, GIST-001_0 to GIST-246_0\n",
            "Columns: 494 entries, label to PREDICT_original_phasef_phasesym_entropy_WL3_N5\n",
            "dtypes: float64(468), int64(26)\n",
            "memory usage: 951.3+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ID\n",
              "GIST-001_0    False\n",
              "GIST-002_0    False\n",
              "GIST-003_0    False\n",
              "GIST-004_0    False\n",
              "GIST-005_0    False\n",
              "              ...  \n",
              "GIST-242_0    False\n",
              "GIST-243_0    False\n",
              "GIST-244_0    False\n",
              "GIST-245_0    False\n",
              "GIST-246_0    False\n",
              "Length: 246, dtype: bool"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load data\n",
        "data = load_data()\n",
        "\n",
        "data['label'] = data['label'].map({'non-GIST': 0, 'GIST': 1})\n",
        "\n",
        "y = data['label']\n",
        "x = data.drop(columns=['label'])\n",
        "\n",
        "# Calculate basic statistics\n",
        "n_samples = len(y)\n",
        "n_features = len(x.columns)\n",
        "\n",
        "n_missing = data.isna().sum().sum()\n",
        "n_zero = (data == 0).sum().sum()\n",
        "\n",
        "# Print basic statistics\n",
        "print(f'The number of samples: {n_samples}')\n",
        "print(f'The number of features: {n_features}')\n",
        "print(f'The number of datapoints: {n_samples * n_features}')\n",
        "print(f\"The number of missing values: {n_missing}\")\n",
        "print(f\"The number of zero values: {n_zero}\")\n",
        "\n",
        "data.info()\n",
        "data.describe()\n",
        "data.duplicated()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58fMBhfq4yi-"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfsUlS1RFb35",
        "outputId": "86538058-e79b-46ef-959d-32d605360978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 246 entries, 0 to 245\n",
            "Data columns (total 50 columns):\n",
            " #   Column                                                        Non-Null Count  Dtype  \n",
            "---  ------                                                        --------------  -----  \n",
            " 0   PREDICT_original_sf_rad_dist_avg_2.5D                         246 non-null    float64\n",
            " 1   PREDICT_original_sf_rad_dist_std_2.5D                         246 non-null    float64\n",
            " 2   PREDICT_original_sf_area_avg_2.5D                             246 non-null    float64\n",
            " 3   PREDICT_original_sf_area_std_2.5D                             246 non-null    float64\n",
            " 4   PREDICT_original_hf_median                                    246 non-null    float64\n",
            " 5   PREDICT_original_logf_entropy_sigma1                          246 non-null    float64\n",
            " 6   PREDICT_original_logf_entropy_sigma5                          246 non-null    float64\n",
            " 7   PREDICT_original_logf_entropy_sigma10                         246 non-null    float64\n",
            " 8   PREDICT_original_tf_LBP_entropy_R3_P12                        246 non-null    float64\n",
            " 9   PREDICT_original_tf_LBP_entropy_R8_P24                        246 non-null    float64\n",
            " 10  PREDICT_original_tf_LBP_entropy_R15_P36                       246 non-null    float64\n",
            " 11  PREDICT_original_tf_GLCMMS_dissimilarityd3.0A0.0mean          246 non-null    float64\n",
            " 12  PREDICT_original_tf_GLCMMS_dissimilarityd3.0A0.0std           246 non-null    float64\n",
            " 13  PREDICT_original_tf_GLCMMS_dissimilarityd3.0A0.79mean         246 non-null    float64\n",
            " 14  PREDICT_original_tf_GLCMMS_dissimilarityd3.0A1.57std          246 non-null    float64\n",
            " 15  PREDICT_original_tf_GLCMMS_dissimilarityd3.0A2.36std          246 non-null    float64\n",
            " 16  PREDICT_original_tf_GLCMMS_homogeneityd3.0A0.0mean            246 non-null    float64\n",
            " 17  PREDICT_original_tf_GLCMMS_homogeneityd3.0A0.0std             246 non-null    float64\n",
            " 18  PREDICT_original_tf_GLCMMS_homogeneityd3.0A0.79mean           246 non-null    float64\n",
            " 19  PREDICT_original_tf_GLCMMS_homogeneityd3.0A0.79std            246 non-null    float64\n",
            " 20  PREDICT_original_tf_GLCMMS_homogeneityd3.0A1.57mean           246 non-null    float64\n",
            " 21  PREDICT_original_tf_GLCMMS_homogeneityd3.0A1.57std            246 non-null    float64\n",
            " 22  PREDICT_original_tf_GLCMMS_homogeneityd3.0A2.36mean           246 non-null    float64\n",
            " 23  PREDICT_original_tf_GLCMMS_homogeneityd3.0A2.36std            246 non-null    float64\n",
            " 24  PREDICT_original_tf_Gabor_kurtosis_F0.05_A0.0                 246 non-null    float64\n",
            " 25  PREDICT_original_tf_Gabor_entropy_F0.05_A0.0                  246 non-null    float64\n",
            " 26  PREDICT_original_tf_Gabor_entropy_F0.05_A0.79                 246 non-null    float64\n",
            " 27  PREDICT_original_tf_Gabor_entropy_F0.05_A1.57                 246 non-null    float64\n",
            " 28  PREDICT_original_tf_Gabor_median_F0.05_A2.36                  246 non-null    float64\n",
            " 29  PREDICT_original_tf_Gabor_kurtosis_F0.05_A2.36                246 non-null    float64\n",
            " 30  PREDICT_original_tf_Gabor_peak_F0.05_A2.36                    246 non-null    float64\n",
            " 31  PREDICT_original_tf_Gabor_entropy_F0.05_A2.36                 246 non-null    float64\n",
            " 32  PREDICT_original_tf_Gabor_entropy_F0.2_A0.0                   246 non-null    float64\n",
            " 33  PREDICT_original_tf_Gabor_mean_F0.2_A0.79                     246 non-null    float64\n",
            " 34  PREDICT_original_tf_Gabor_entropy_F0.2_A0.79                  246 non-null    float64\n",
            " 35  PREDICT_original_tf_Gabor_mean_F0.2_A1.57                     246 non-null    float64\n",
            " 36  PREDICT_original_tf_Gabor_entropy_F0.2_A1.57                  246 non-null    float64\n",
            " 37  PREDICT_original_tf_Gabor_mean_F0.2_A2.36                     246 non-null    float64\n",
            " 38  PREDICT_original_tf_Gabor_entropy_F0.2_A2.36                  246 non-null    float64\n",
            " 39  PREDICT_original_tf_Gabor_entropy_F0.5_A0.0                   246 non-null    float64\n",
            " 40  PREDICT_original_tf_Gabor_mean_F0.5_A0.79                     246 non-null    float64\n",
            " 41  PREDICT_original_tf_Gabor_entropy_F0.5_A0.79                  246 non-null    float64\n",
            " 42  PREDICT_original_tf_Gabor_entropy_F0.5_A1.57                  246 non-null    float64\n",
            " 43  PREDICT_original_tf_Gabor_mean_F0.5_A2.36                     246 non-null    float64\n",
            " 44  PREDICT_original_tf_Gabor_entropy_F0.5_A2.36                  246 non-null    float64\n",
            " 45  PREDICT_original_vf_Frangi_full_energy_SR(1.0, 10.0)_SS2.0    246 non-null    float64\n",
            " 46  PREDICT_original_vf_Frangi_full_entropy_SR(1.0, 10.0)_SS2.0   246 non-null    float64\n",
            " 47  PREDICT_original_vf_Frangi_edge_energy_SR(1.0, 10.0)_SS2.0    246 non-null    float64\n",
            " 48  PREDICT_original_vf_Frangi_edge_entropy_SR(1.0, 10.0)_SS2.0   246 non-null    float64\n",
            " 49  PREDICT_original_vf_Frangi_inner_entropy_SR(1.0, 10.0)_SS2.0  246 non-null    float64\n",
            "dtypes: float64(50)\n",
            "memory usage: 96.2 KB\n",
            "None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lucas\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [ 77  84  90  97 103 110 467 474 475 480 487 488] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "c:\\Users\\lucas\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=50)  # or 50, or try multiple values\n",
        "x_reduced_array = selector.fit_transform(x, y)\n",
        "selected_feature_names = x.columns[selector.get_support()]\n",
        "x_reduced = pd.DataFrame(x_reduced_array, columns=selected_feature_names)\n",
        "print(x_reduced.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3rxAizdX-5K",
        "outputId": "73023844-071e-4630-8a36-71e012684a13"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (3628296233.py, line 11)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    merged_data = pd.concat([x_reduced[top_features], y)], axis=1)\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate variance for each feature\n",
        "feature_variances = x_reduced.var()\n",
        "\n",
        "# Select the top 5 features with the highest variance\n",
        "top_features = feature_variances.nlargest(5).index\n",
        "\n",
        "# Merge the top features with the label\n",
        "merged_data = pd.concat([x_reduced[top_features], y)], axis=1)\n",
        "\n",
        "# Create a seaborn pairplot for the top features with colors based on labels\n",
        "sns.pairplot(merged_data, hue='label', diag_kind=\"kde\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PREDICT_original_sf_compactness_avg_2.5D  \\\n",
            "0                                     False   \n",
            "\n",
            "   PREDICT_original_sf_compactness_std_2.5D  \\\n",
            "0                                     False   \n",
            "\n",
            "   PREDICT_original_sf_rad_dist_avg_2.5D  \\\n",
            "0                                  False   \n",
            "\n",
            "   PREDICT_original_sf_rad_dist_std_2.5D  \\\n",
            "0                                  False   \n",
            "\n",
            "   PREDICT_original_sf_roughness_avg_2.5D  \\\n",
            "0                                   False   \n",
            "\n",
            "   PREDICT_original_sf_roughness_std_2.5D  \\\n",
            "0                                   False   \n",
            "\n",
            "   PREDICT_original_sf_convexity_avg_2.5D  \\\n",
            "0                                   False   \n",
            "\n",
            "   PREDICT_original_sf_convexity_std_2.5D  PREDICT_original_sf_cvar_avg_2.5D  \\\n",
            "0                                   False                              False   \n",
            "\n",
            "   PREDICT_original_sf_cvar_std_2.5D  ...  \\\n",
            "0                              False  ...   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_median_WL3_N5  \\\n",
            "0                                           False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_std_WL3_N5  \\\n",
            "0                                        False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_skewness_WL3_N5  \\\n",
            "0                                             False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_kurtosis_WL3_N5  \\\n",
            "0                                             False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_peak_WL3_N5  \\\n",
            "0                                          True   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_peak_position_WL3_N5  \\\n",
            "0                                               True       \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_range_WL3_N5  \\\n",
            "0                                          False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_energy_WL3_N5  \\\n",
            "0                                           False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_quartile_range_WL3_N5  \\\n",
            "0                                              False        \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_entropy_WL3_N5  \n",
            "0                                             True  \n",
            "\n",
            "[1 rows x 493 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/scipy/stats/_axis_nan_policy.py:586: UserWarning: scipy.stats.shapiro: Input data has range zero. The results may not be accurate.\n",
            "  res = hypotest_fun_out(*samples, **kwds)\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "def check_normal_distribution(data, alpha=0.05):\n",
        "    results = {}\n",
        "    for col in data.columns:\n",
        "        p = shapiro(data[col])[1]\n",
        "        results[col] = p > alpha\n",
        "    return pd.DataFrame([results])\n",
        "\n",
        "results = check_normal_distribution(x)\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
