{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "19dab814-7aba-4a1a-8263-730f58ce7c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ktml (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-9HbZdwFb33"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VV0YLd6oHgen"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "\n",
        "from worcgist.load_data import load_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "fe88fb9a-de34-47cf-c8b4-c002d3515cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 246\n",
            "The number of features: 493\n",
            "The number of datapoints: 121278\n",
            "The number of missing values: 0\n",
            "The number of zero values: 6848\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 246 entries, GIST-001_0 to GIST-246_0\n",
            "Columns: 494 entries, label to PREDICT_original_phasef_phasesym_entropy_WL3_N5\n",
            "dtypes: float64(468), int64(26)\n",
            "memory usage: 951.3+ KB\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "data = load_data()\n",
        "\n",
        "data['label'] = data['label'].map({'non-GIST': 0, 'GIST': 1})\n",
        "\n",
        "y = data['label']\n",
        "x = data.drop(columns=['label'])\n",
        "\n",
        "# Calculate basic statistics\n",
        "n_samples = len(y)\n",
        "n_features = len(x.columns)\n",
        "\n",
        "n_missing = data.isna().sum().sum()\n",
        "n_zero = (data == 0).sum().sum()\n",
        "\n",
        "# Print basic statistics\n",
        "print(f'The number of samples: {n_samples}')\n",
        "print(f'The number of features: {n_features}')\n",
        "print(f'The number of datapoints: {n_samples * n_features}')\n",
        "print(f\"The number of missing values: {n_missing}\")\n",
        "print(f\"The number of zero values: {n_zero}\")\n",
        "\n",
        "data.info()\n",
        "#data.describe()\n",
        "#data.duplicated()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58fMBhfq4yi-"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39h_BEytwUpj",
        "outputId": "6dcd58b9-0285-432b-88d1-643a561565fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PREDICT_original_sf_compactness_avg_2.5D  \\\n",
            "0                                     False   \n",
            "\n",
            "   PREDICT_original_sf_compactness_std_2.5D  \\\n",
            "0                                     False   \n",
            "\n",
            "   PREDICT_original_sf_rad_dist_avg_2.5D  \\\n",
            "0                                  False   \n",
            "\n",
            "   PREDICT_original_sf_rad_dist_std_2.5D  \\\n",
            "0                                  False   \n",
            "\n",
            "   PREDICT_original_sf_roughness_avg_2.5D  \\\n",
            "0                                   False   \n",
            "\n",
            "   PREDICT_original_sf_roughness_std_2.5D  \\\n",
            "0                                   False   \n",
            "\n",
            "   PREDICT_original_sf_convexity_avg_2.5D  \\\n",
            "0                                   False   \n",
            "\n",
            "   PREDICT_original_sf_convexity_std_2.5D  PREDICT_original_sf_cvar_avg_2.5D  \\\n",
            "0                                   False                              False   \n",
            "\n",
            "   PREDICT_original_sf_cvar_std_2.5D  ...  \\\n",
            "0                              False  ...   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_median_WL3_N5  \\\n",
            "0                                           False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_std_WL3_N5  \\\n",
            "0                                        False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_skewness_WL3_N5  \\\n",
            "0                                             False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_kurtosis_WL3_N5  \\\n",
            "0                                             False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_peak_WL3_N5  \\\n",
            "0                                          True   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_peak_position_WL3_N5  \\\n",
            "0                                               True       \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_range_WL3_N5  \\\n",
            "0                                          False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_energy_WL3_N5  \\\n",
            "0                                           False   \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_quartile_range_WL3_N5  \\\n",
            "0                                              False        \n",
            "\n",
            "   PREDICT_original_phasef_phasesym_entropy_WL3_N5  \n",
            "0                                             True  \n",
            "\n",
            "[1 rows x 493 columns]\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "def check_normal_distribution(data, alpha=0.05):\n",
        "    results = {}\n",
        "    for col in data.columns:\n",
        "        p = shapiro(data[col])[1]\n",
        "        results[col] = p > alpha\n",
        "    return pd.DataFrame([results])\n",
        "\n",
        "results = check_normal_distribution(x)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "# Outlier removal based on normal-distribution assumption\n",
        "\n",
        "def replace_outliers(df, is_normal):\n",
        "    \"\"\"\n",
        "    Replace outliers in the given DataFrame based on the distribution type of each column.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The input DataFrame containing numerical data.\n",
        "    is_normal (pd.Series): A Series indicating whether each column in the DataFrame is normally distributed (True) or not (False).\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: The DataFrame with outliers replaced by the respective bounds.\n",
        "    \"\"\"\n",
        "    threshold_nd = 1  # z-score threshold for normally distributed data\n",
        "    threshold_nnd = 5  # IQR threshold for non-normally distributed data\n",
        "    for column in df.columns:\n",
        "        if is_normal[column]:\n",
        "            # Use z-score for normally distributed columns\n",
        "            mean = df[column].mean()\n",
        "            std = df[column].std()\n",
        "            lower_bound = mean - threshold_nd * std\n",
        "            upper_bound = mean + threshold_nd * std\n",
        "            outliers = (df[column] > upper_bound) | (df[column] < lower_bound)\n",
        "            df.loc[df[column] > upper_bound, column] = upper_bound\n",
        "            df.loc[df[column] < lower_bound, column] = lower_bound\n",
        "        else:\n",
        "            # Use IQR for non-normally distributed columns\n",
        "            Q1 = df[column].quantile(0.25)\n",
        "            Q3 = df[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - threshold_nnd * IQR\n",
        "            upper_bound = Q3 + threshold_nnd * IQR\n",
        "            outliers = (df[column] > upper_bound) | (df[column] < lower_bound)\n",
        "            df.loc[df[column] > upper_bound, column] = upper_bound\n",
        "            df.loc[df[column] < lower_bound, column] = lower_bound\n",
        "    return df\n",
        "\n",
        "df_no_outliers = replace_outliers(x.copy(), results.iloc[0])\n",
        "print(\"Max of original data (first 5 columns):\")\n",
        "print(x.iloc[:, 50:65].describe().loc['max'])\n",
        "print(\"Max of data without outliers (first 5 columns):\")\n",
        "print(df_no_outliers.iloc[:, 50:65].describe().loc['max'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1HD1S8jwd3s",
        "outputId": "4773fe18-987f-43cb-f195-80db2199b8c5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max of original data (first 5 columns):\n",
            "PREDICT_original_logf_min_sigma5              -1.457042e+02\n",
            "PREDICT_original_logf_max_sigma5               2.853151e+02\n",
            "PREDICT_original_logf_mean_sigma5             -2.430822e+00\n",
            "PREDICT_original_logf_median_sigma5            7.490527e-01\n",
            "PREDICT_original_logf_std_sigma5               1.289628e+02\n",
            "PREDICT_original_logf_skewness_sigma5          4.438505e-01\n",
            "PREDICT_original_logf_kurtosis_sigma5          9.023666e+00\n",
            "PREDICT_original_logf_peak_sigma5              4.047937e-01\n",
            "PREDICT_original_logf_peak_position_sigma5     3.550000e+01\n",
            "PREDICT_original_logf_range_sigma5             5.806304e+02\n",
            "PREDICT_original_logf_energy_sigma5            1.758992e+11\n",
            "PREDICT_original_logf_quartile_range_sigma5    6.186428e+01\n",
            "PREDICT_original_logf_entropy_sigma5           1.566434e+01\n",
            "PREDICT_original_logf_min_sigma10             -1.177465e+02\n",
            "PREDICT_original_logf_max_sigma10              3.210932e+02\n",
            "Name: max, dtype: float64\n",
            "Max of data without outliers (first 5 columns):\n",
            "PREDICT_original_logf_min_sigma5              -1.457042e+02\n",
            "PREDICT_original_logf_max_sigma5               2.853151e+02\n",
            "PREDICT_original_logf_mean_sigma5             -2.430822e+00\n",
            "PREDICT_original_logf_median_sigma5            7.490527e-01\n",
            "PREDICT_original_logf_std_sigma5               1.289628e+02\n",
            "PREDICT_original_logf_skewness_sigma5          4.438505e-01\n",
            "PREDICT_original_logf_kurtosis_sigma5          9.023666e+00\n",
            "PREDICT_original_logf_peak_sigma5              4.047937e-01\n",
            "PREDICT_original_logf_peak_position_sigma5     3.550000e+01\n",
            "PREDICT_original_logf_range_sigma5             5.806304e+02\n",
            "PREDICT_original_logf_energy_sigma5            1.758992e+11\n",
            "PREDICT_original_logf_quartile_range_sigma5    6.186428e+01\n",
            "PREDICT_original_logf_entropy_sigma5           1.565935e+01\n",
            "PREDICT_original_logf_min_sigma10             -1.177465e+02\n",
            "PREDICT_original_logf_max_sigma10              3.210932e+02\n",
            "Name: max, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "source": [
        "def replace_outliers(df, is_normal):\n",
        "    \"\"\"\n",
        "    Replace outliers in the given DataFrame based on the distribution type of each column.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): The input DataFrame containing numerical data.\n",
        "    is_normal (pd.Series): A Series indicating whether each column in the DataFrame is normally distributed (True) or not (False).\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: The DataFrame with outliers replaced by the respective bounds.\n",
        "    list: A list of all outlier values found.\n",
        "    \"\"\"\n",
        "    threshold_nd = 1  # z-score threshold for normally distributed data\n",
        "    threshold_nnd = 5  # IQR threshold for non-normally distributed data\n",
        "    outliers_list = []  # Initialize an empty list to store outliers\n",
        "\n",
        "    for column in df.columns:\n",
        "        if is_normal[column]:\n",
        "            # Use z-score for normally distributed columns\n",
        "            mean = df[column].mean()\n",
        "            std = df[column].std()\n",
        "            lower_bound = mean - threshold_nd * std\n",
        "            upper_bound = mean + threshold_nd * std\n",
        "            outliers = (df[column] > upper_bound) | (df[column] < lower_bound)\n",
        "            outliers_list.extend(df.loc[outliers, column].tolist())  # Append outliers to the list\n",
        "            df.loc[df[column] > upper_bound, column] = upper_bound\n",
        "            df.loc[df[column] < lower_bound, column] = lower_bound\n",
        "        else:\n",
        "            # Use IQR for non-normally distributed columns\n",
        "            Q1 = df[column].quantile(0.25)\n",
        "            Q3 = df[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - threshold_nnd * IQR\n",
        "            upper_bound = Q3 + threshold_nnd * IQR\n",
        "            outliers = (df[column] > upper_bound) | (df[column] < lower_bound)\n",
        "            outliers_list.extend(df.loc[outliers, column].tolist())  # Append outliers to the list\n",
        "            df.loc[df[column] > upper_bound, column] = upper_bound\n",
        "            df.loc[df[column] < lower_bound, column] = lower_bound\n",
        "\n",
        "    return df, outliers_list  # Return the modified DataFrame and the outliers list\n",
        "df_no_outliers = replace_outliers(x, results.iloc[0])\n",
        "x = df_no_outliers # assign the result back to x\n",
        "print(\"Max of original data (first 5 columns):\")\n",
        "print(x.iloc[:, 10:20].describe().loc['max'])\n",
        "print(\"Max of data without outliers (first 5 columns):\")\n",
        "print(df_no_outliers.iloc[:, 10:20].describe().loc['max'])\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JcW91DAs3BD5",
        "outputId": "59b7de07-0b08-499f-8aad-4b5de8b495c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max of original data (first 5 columns):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'iloc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-3b54a026cb14>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_no_outliers\u001b[0m \u001b[0;31m# assign the result back to x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max of original data (first 5 columns):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max of data without outliers (first 5 columns):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_no_outliers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'iloc'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "0dyRjEnQyOdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "selector = SelectKBest(score_func=f_classif, k=50)  # or 50, or try multiple values\n",
        "x_reduced_array = selector.fit_transform(x, y)\n",
        "selected_feature_names = x.columns[selector.get_support()]\n",
        "x_reduced = pd.DataFrame(x_reduced_array, columns=selected_feature_names)\n",
        "#print(x_reduced.info())"
      ],
      "metadata": {
        "id": "wLFsdLAWyVpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}